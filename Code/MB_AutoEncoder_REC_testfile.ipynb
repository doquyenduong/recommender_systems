{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Source: https://www.youtube.com/watch?v=LjRvMUk59PI\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deezer Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7528398 entries, 0 to 7558833\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype\n",
      "---  ------           -----\n",
      " 0   genre_id         int64\n",
      " 1   context_type     int64\n",
      " 2   platform_name    int64\n",
      " 3   platform_family  int64\n",
      " 4   listen_type      int64\n",
      " 5   user_gender      int64\n",
      " 6   user_age         int64\n",
      " 7   is_listened      int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 516.9 MB\n",
      "None\n",
      "(5000000, 8)\n",
      "(2528398, 8)\n",
      "[[10  1  2 ...  0 25  1]\n",
      " [10  4  0 ...  0 23  1]\n",
      " [10 23  1 ...  0 28  0]\n",
      " ...\n",
      " [ 0  4  0 ...  0 26  0]\n",
      " [ 0  4  0 ...  1 29  1]\n",
      " [ 0  4  0 ...  1 30  1]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/train.csv').iloc[:, [0, 2, 3, 4, 6, 7, 9, 10, 11, 13, 14]]\n",
    "\n",
    "d1 = data.groupby('user_id')['is_listened'].sum()\n",
    "d2 = d1[d1 > 10].index\n",
    "d3 = data[data.user_id.isin(d2)].iloc[:, [0, 3, 4, 5, 6, 7, 9, 10]]  #[0, 3, 4, 5, 6, 7, 9]\n",
    "\n",
    "#df_r = pd.pivot_table(d3, index=['user_id'], columns=['media_id'], values=['is_listened'], fill_value=0).astype(int)\n",
    "\n",
    "print(d3.info())\n",
    "cutoff = 5000000\n",
    "x_train_NN = d3.iloc[:cutoff, :].to_numpy()\n",
    "x_test_NN = d3.iloc[cutoff:,:].to_numpy()\n",
    "print(x_train_NN.shape)\n",
    "print(x_test_NN.shape)\n",
    "print(x_test_NN)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the Architecture of an Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_43 (InputLayer)       [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 8)                 32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59\n",
      "Trainable params: 59\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This is the size of our encoded representations\n",
    "encoding_dim = int(round(x_train_NN.shape[1] / 3, 0))   # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(x_train_NN.shape[1],))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img) # ,activity_regularizer=regularizers.l1(10e-5)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(x_train_NN.shape[1], activation='relu')(encoded)#,kernel_regularizer=l2(0.0001)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()\n",
    "# This model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer=SGD(learning_rate=0.25, momentum=0.9), loss='MSE', metrics=['accuracy', 'mse'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "78126/78126 [==============================] - 104s 1ms/step - loss: 23497054466878596024631296.0000 - accuracy: 0.2668 - mse: 23497054466878596024631296.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 2/10\n",
      "78126/78126 [==============================] - 103s 1ms/step - loss: 22644558.0000 - accuracy: 0.2668 - mse: 22644558.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 3/10\n",
      "78126/78126 [==============================] - 108s 1ms/step - loss: 22646224.0000 - accuracy: 0.2668 - mse: 22646224.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 4/10\n",
      "78126/78126 [==============================] - 146s 2ms/step - loss: 22644188.0000 - accuracy: 0.2668 - mse: 22644188.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 5/10\n",
      "78126/78126 [==============================] - 121s 2ms/step - loss: 22644772.0000 - accuracy: 0.2668 - mse: 22644772.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 6/10\n",
      "78126/78126 [==============================] - 124s 2ms/step - loss: 22649296.0000 - accuracy: 0.2668 - mse: 22649296.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 7/10\n",
      "78126/78126 [==============================] - 117s 1ms/step - loss: 22642062.0000 - accuracy: 0.2668 - mse: 22642062.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 8/10\n",
      "78126/78126 [==============================] - 110s 1ms/step - loss: 22647946.0000 - accuracy: 0.2668 - mse: 22647946.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 9/10\n",
      "78126/78126 [==============================] - 119s 2ms/step - loss: 22641928.0000 - accuracy: 0.2668 - mse: 22641928.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n",
      "Epoch 10/10\n",
      "78106/78126 [============================>.] - ETA: 0s - loss: 22645122.0000 - accuracy: 0.2668 - mse: 22645122.0000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 781260 batches). You may need to use the repeat() function when building your dataset.\n",
      "78126/78126 [==============================] - 107s 1ms/step - loss: 22646026.0000 - accuracy: 0.2668 - mse: 22646026.0000 - val_loss: 20903260.0000 - val_accuracy: 0.2618 - val_mse: 20903260.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x18bb490aee0>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "autoencoder.fit(x_train_NN, x_train_NN,\n",
    "                epochs=10,\n",
    "                batch_size= batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_NN, x_test_NN),\n",
    "                steps_per_epoch=x_train_NN.shape[0] // batch_size + 1,\n",
    "                validation_steps=x_test_NN.shape[0] // batch_size + 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test_NN)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(np.around(decoded_imgs, 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "           0    1    2    3    4    5    6    7\n2528393  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n2528394  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n2528395  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n2528396  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n2528397  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2528393</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2528394</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2528395</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2528396</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2528397</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(decoded_imgs)\n",
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}